# Start of day

I start by looking into some research on sentiment analysis models to get some inspiration. Timestamp: 11:02
quick note to the problem of not deterministic results: Could reduce the temperature to reduce the creative freedom of
the models!

## SA or opinion mining a review (2017)

https://www.researchgate.net/profile/Saidah-Saad/publication/320748824_Sentiment_Analysis_or_Opinion_Mining_A_Review/links/5a8f629ca6fdccecffffdf0a/Sentiment-Analysis-or-Opinion-Mining-A-Review.pdf
We differentiate between sentiment analsis, opinion mining, subjectivity analysis and sentiment orientation. It
represents a combination of NLP ML and computational linguistics. This can happen at the document, sentence or word
level. Semantic based analysis and ML are the most prevalent techniques. Their combination is also common.

SA deals with opinions and sentiments of a group of people concerning a specific topic. It is popular in politics,
business and marketing. The base assumption is that the text carries a sentiment, while often such documents only
contain facts. Even more sentimental texts may include statements that are not opinionated. Identifying facts and
sentiment is at the core of SA. The process includes sentiment classification, subjective analysis, opinion holder
extraction and aspect or object based extraction.
Subjectivity classification handles classification into objective and subjective sentences, discarding objective ones
and further exploring subjective ones. Subjective sentences are further classified into positive, negative and neutral.

See source 3 and 12 for a study on polarities

# ML approach

General supervised learning approach. SVM, Naive Bayes and Maximum Entropy are popular and highly successful.

# Lexicon based approach

Semantic orientation uses an unsupervised learning approach without initial training. It basically defines a distance
from positive and negative poles of a word. The application of lexical rules is center to this approach, using e.g.
WordNet as a prime lexical source. Main difficulty here is the construction of relevant and reliable lexicons.

# Combination Method

It's a rare practice, e.g. using n-grams in combination with lexicons to increase accuracy or using lexicons to improve
naive bayes. The authors do see this as a great opportunity.

## A Review of Natural Language Processing Techniques for Sentiment Analysis using Pre-trained Models (2020)

https://ieeexplore.ieee.org/abstract/document/9076502
Choice of embedding makes a big difference. Using pre-trained embeddings seems the most promising!

# Pre-trained models

We are looking at transformer based models and are interested in transfer learning approaches. ULMFiT, GPT-2, BiGRU,
BERT, Transformer-XL and XLNet.

ULMFiT, or Universal Language Model Fine-Tuning (2018), is trained on Wikitext 103 datasets and can then be fine-tuned
to specific tasks.

GPT-2, or Generative Pre-trained Transformer 2 (2019), is trained on WebText and has next word prediction as main task
in training. It specializes in text generation and performs well in QA, reading comprehension, summarization and
translation tasks.

BiGRU, or Bidirectional Gated Recurrent Unit (2014), is a variant of the GRU that uses a bidirectional approach to
compensate for the short term memory problem of classic RNNs. The usage of gates to regulate the flow of information
sets it apart. It finds uses in many deep learning applications, such as speech synthesis, speech recognition and
natural language understanding.

BERT, or Bidirectional Encoder Representations from Transformers (2018), considers the context of a word on both sides.
It can perform different NLP tasks simultaneously and represents the first such model that is trained unsupervised,
useful for multitask learning and bidirectional. BERT also has many variants, such as RoBERTa, DistilBERT, ALBERT and
T5 that improve on its shortcomings.

Transformer-XL is about 1800 times faster than the regular Transformer. If interested look into the original paper, the
stuff written here barely makes any sense.

XLNet is a generalized autoregressive pretraining model that combines the best of BERT and Transformer-XL. It introduces
permutation language modeling as objective in pretraining, setting it apart from the often used next word/sentence
prediction and masking approaches found in other models. XLNet is next to BERT the most promising candidate for my
problem. However, it is computationally expensive.

# Efficient utilization of pre-trained models: A review of sentiment analysis

via prompt learning (2024)

https://www.sciencedirect.com/science/article/pii/S0950705123008985?ref=cra_js_challenge&fr=RR-1
Alternative to classical fine tuning, less data and compute expensive. We add templates to the input to improve
performance.

source 4 discusses aspect based sentiment analysis, discussing sentiment polarity. Subtasks of ABSA are ATE (aspect term
extraction), ACD (Aspect category detection), ASC (Aspecet sentiment classification), OTE (Opinion term extraction),
ASQP (Aspect Sentiment Quad Prediction)..

If prompt tuning is used in my work, this paper does a good deep dive into the topic. Maybe, prompt tuning the
active llama3.1 instance is the way to go. Instead of sampling possible answers I could either find a way to find an
optimal encoding to improve the quality of given answers, e.g. using templates specific to the task at hand, or actually
use the RL agent to produce templates/prompts. LEPRO: Learning to Prompt with RL; RL Prompt Tuning:

Alternatively: Find a way that the RL Agent proposes an optimal solution and use the PRewrite idea, s.t. it generates a
prompt that would result in a similar response. (If there is no actual need for fine-tuning we could simply use an API
instead of hosting another model to save compute)
RLPrompt and TEMPERA are previous works in a similar direction (They do have more shortcomings but might be more
feasible or easier to implement)
IRL may be useful for fine-tuning of the third LLM (https://www.sciencedirect.com/science/article/pii/S0004370221000515)

# CURRENT IDEA: SENTIMENT ANALYSIS AS STATE SPACE; FIND OPTIMAL TARGET SPACE; CHOOSE ACTION AS GENERATING A PROMPT RATHER THAN A RESPONSE

Alternative : Prompt rewriting with RL
PROBLEM: Find a relevant state space. Find a framework that can produce prompts/templates to actually achieve the goals
prompt tuning the second actor LLM via fine-tuning a third LLM, e.g. GPT-2, via RL. This fine-tuning is w.r.t. producing
optimized prompts. See Prompt rewriting with RL paper below
Need to return to this paper later again!

# BERT and its successors in SA

https://link.springer.com/article/10.1186/s40537-023-00781-w

# Prompt rewriting with RL

https://arxiv.org/abs/2401.08189

## What was achieved today?

- Looked into sentiment analysis models
- Found a promising approach to use prompt tuning to optimize the second actors responses
- Still probably going to use a BERT model for SA, but still need to think about how to do it exactly. Maybe it is
  actually useful to have the small state space, but need to find a way to represent trends within it, if I am not
  mistaken it should be a probability distribution over the three states, thus removing the output layer should yield
  what I need. This would allow me to get a better idea of what is going on. Furthermore, using specific focus words,
  i.e. the topic that the position on is supposed to be shifted, via some sort of ASBA seems promising.
- I think it is possible or even probable that I will either use the open AI API to host a model, or locally host
  another one, e.g. GPT2 that I then fine tune, that interacts with my RL Agent to create prompts for the second actor
  that should optimize performance.
- I had many, many ideas today. Now I need to try some out. Let's do that tomorrow and just think about it for today.

I guess that's it for today. I am so tired. Timestamp: 15:14